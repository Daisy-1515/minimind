# MiniMind - æç®€ Transformer å®ç°

[](https://www.python.org/)
[](https://pytorch.org/)
[](https://huggingface.co/transformers/)
[](https://www.google.com/search?q=LICENSE)

## ğŸ“– ç®€ä»‹

MiniMind æ˜¯ä¸€ä¸ªæç®€çš„ Transformer è¯­è¨€æ¨¡å‹å®ç°ã€‚å®ƒåŒ…å«äº†ä¸€ç³»åˆ—ç°ä»£ LLM çš„æ ¸å¿ƒæŠ€æœ¯ç»„ä»¶ï¼Œä»£ç ç»“æ„æ¸…æ™°ï¼Œæ˜“äºå­¦ä¹ å’Œæ‰©å±•ã€‚

### âœ¨ æ ¸å¿ƒç‰¹æ€§

  - **åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ› (GQA)**: ä¼˜åŒ– KV ç¼“å­˜ï¼Œæå‡æ¨ç†é€Ÿåº¦ã€‚
  - **æ—‹è½¬ä½ç½®ç¼–ç  (RoPE)**: å¢å¼ºæ¨¡å‹çš„ä½ç½®æ„ŸçŸ¥èƒ½åŠ›ï¼Œæ”¯æŒå¤–æ¨ã€‚
  - **RMS å½’ä¸€åŒ–**: æ›¿ä»£ LayerNormï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ã€‚
  - **SwiGLU æ¿€æ´»å‡½æ•°**: ç°ä»£ Transformer æ ‡é…ï¼Œä¼˜äº ReLUã€‚
  - **Flash Attention**: é›†æˆ PyTorch 2.0+ çš„åŠ é€Ÿç®—å­ã€‚
  - **YaRN é•¿ä¸Šä¸‹æ–‡**: æ”¯æŒä¸Šä¸‹æ–‡çª—å£æ‰©å±•ã€‚
  - **æ··åˆä¸“å®¶æ¨¡å‹ (MoE)**: (è®¡åˆ’ä¸­) æ”¯æŒç¨€ç–æ··åˆä¸“å®¶æ¶æ„ã€‚
  - **ç»“æ„æ¸…æ™°**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºé˜…è¯»ã€‚
  - **ä»é›¶é¢„è®­ç»ƒ**: åŒ…å«å®Œæ•´çš„é¢„è®­ç»ƒæµç¨‹ã€‚

## ğŸ“‚ ç›®å½•ç»“æ„

```
minimind/
â”œâ”€â”€ model/                  # æ¨¡å‹æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ model.py           # MokioMind ä¸»æ¨¡å‹æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ MokioMindConfig      # é…ç½®ç±»
â”‚   â”‚   â”œâ”€â”€ Attention            # æ³¨æ„åŠ›æœºåˆ¶
â”‚   â”‚   â”œâ”€â”€ FeedForward          # SwiGLU å‰é¦ˆç½‘ç»œ
â”‚   â”‚   â”œâ”€â”€ MokioMindBlock       # Transformer å±‚
â”‚   â”‚   â”œâ”€â”€ MokioMindModel       # æ¨¡å‹ä¸»ä½“
â”‚   â”‚   â””â”€â”€ MokioMindForCausalLM # å› æœè¯­è¨€æ¨¡å‹å¤´
â”‚
â”œâ”€â”€ method/                 # æ ¸å¿ƒç®—æ³•å®ç°
â”‚   â”œâ”€â”€ rope.py            # æ—‹è½¬ä½ç½®ç¼–ç  (RoPE)
â”‚   â”‚   â”œâ”€â”€ precompute_freqs_cis # é¢„è®¡ç®—é¢‘ç‡
â”‚   â”‚   â””â”€â”€ apply_rotary_pos_emb # åº”ç”¨ RoPE
â”‚   â”œâ”€â”€ rmsnorm.py         # RMS å½’ä¸€åŒ–å±‚
â”‚   â””â”€â”€ gqa.py             # åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›é€»è¾‘    
â”‚
â”œâ”€â”€ dataset/                # æ•°æ®é›†å¤„ç†
â”‚   â””â”€â”€ lm_dataset.py      # è¯­è¨€æ¨¡å‹æ•°æ®åŠ è½½å™¨    
â”‚
â”œâ”€â”€ trainer/                # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ train_pre.py       # é¢„è®­ç»ƒä¸»å¾ªç¯  
â”‚   â””â”€â”€ trainer_utils.py   # è®­ç»ƒå·¥å…·å‡½æ•° 
â”‚
â”œâ”€â”€ environment/            # ç¯å¢ƒé…ç½®
â”‚   â””â”€â”€ environment.yml    # Conda ç¯å¢ƒæ–‡ä»¶
â”‚
â”œâ”€â”€ main.py                 # æ¨ç†æ¼”ç¤ºè„šæœ¬
â”œâ”€â”€ å¼€å‘æ—¥å¿—.md              # å¼€å‘è¿‡ç¨‹è®°å½•
â”œâ”€â”€ å¸¸è§é—®é¢˜.md              # å¸¸è§ Bug ä¸ä¿®å¤
â””â”€â”€ è·¯çº¿å›¾.md                # é¡¹ç›®æœªæ¥è§„åˆ’
```

## âš™ï¸ å‚æ•°é…ç½®

### æ¨¡å‹å‚æ•°

MiniMind ä½¿ç”¨ä»¥ä¸‹é»˜è®¤å‚æ•°é…ç½®ï¼ˆå¯è‡ªå®šä¹‰ï¼‰ï¼š

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `hidden_size` | 512 | éšè—å±‚ç»´åº¦ |
| `num_attention_heads` | 8 | æ³¨æ„åŠ›å¤´æ•° |
| `num_key_value_heads` | 2 | KV å¤´æ•° (GQA é…ç½®)     |
| `num_hidden_layers` | 8 | Transformer å±‚æ•° |
| `vocab_size` | 6400 | è¯è¡¨å¤§å° |
| `max_position_embeddings` | 32768 | æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ |
| `rope_base` | 1000000 | RoPE åŸºé¢‘ |
| `flash_attention` | True | æ˜¯å¦å¼€å¯ Flash Attention |

### æ ¸å¿ƒæŠ€æœ¯è¯¦è§£

#### 1\. åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ› (GQA)

GQA æ˜¯ Multi-Query Attention (MQA) å’Œ Multi-Head Attention (MHA) çš„æŠ˜ä¸­æ–¹æ¡ˆï¼š

```
åŸå§‹ MHA: 32 Q-heads, 32 KV-heads  (1:1)
GQA:      32 Q-heads, 8 KV-heads   (4x å‹ç¼©)
MQA:      32 Q-heads, 1 KV-head    (32x å‹ç¼©)
```

**ä¼˜åŠ¿**ï¼š

  - å¤§å¹…å‡å°‘ KV Cache æ˜¾å­˜å ç”¨ï¼š`(n_kv_heads / n_heads)`
  - ä¿æŒäº†æ¥è¿‘ MHA çš„æ€§èƒ½ï¼Œé€Ÿåº¦æ¥è¿‘ MQAã€‚

#### 2\. æ—‹è½¬ä½ç½®ç¼–ç  (RoPE)

RoPE é€šè¿‡æ—‹è½¬çŸ©é˜µæ³¨å…¥ç»å¯¹ä½ç½®ä¿¡æ¯ï¼š

```python
# ä¼ªä»£ç 
q_embed = (q * cos) + (rotate_half(q) * sin)
k_embed = (k * cos) + (rotate_half(k) * sin)
```

**ä¼˜åŠ¿**ï¼š

  - å…·æœ‰è‰¯å¥½çš„ç›¸å¯¹ä½ç½®æ€§è´¨ã€‚
  - æ”¯æŒé€šè¿‡ YaRN ç­‰æ–¹æ³•è¿›è¡Œé•¿åº¦å¤–æ¨ã€‚

#### 3\. RMS å½’ä¸€åŒ–

ç›¸æ¯” LayerNormï¼ŒRMSNorm å»é™¤äº†å‡å€¼ä¸­å¿ƒåŒ–ï¼Œè®¡ç®—æ›´ç®€ä¾¿ï¼š

```python
RMS(x) = sqrt(mean(x^2) + eps)
output = weights * (x / RMS(x))
```

**ä¼˜åŠ¿**ï¼š

  - è®¡ç®—å¼€é”€æ›´å°ã€‚
  - åœ¨ LLM è®­ç»ƒä¸­æ›´ç¨³å®šã€‚

#### 4\. SwiGLU æ¿€æ´»å‡½æ•°

ä½¿ç”¨é—¨æ§çº¿æ€§å•å…ƒå˜ä½“ï¼š

```
è¾“å…¥ â†’ up_proj â†’ act_fn â”€â”€â”
                          âŠ— (element-wise) â†’ down_proj â†’ è¾“å‡º
     â†’ gate_proj â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¼˜åŠ¿**ï¼š

  - ç›¸æ¯”æ ‡å‡† FFN æœ‰æ›´å¥½çš„æ€§èƒ½è¡¨ç°ã€‚
  - Llama å’Œ PaLM ç­‰å¤§æ¨¡å‹å‡é‡‡ç”¨æ­¤ç»“æ„ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

  - Python 3.13+
  - PyTorch 2.9.0+
  - Transformers 4.57.1+
  - CUDA 11.8+ (å¦‚éœ€ GPU åŠ é€Ÿ)

### å®‰è£…æ­¥éª¤

#### æ–¹æ³• 1: ä½¿ç”¨ Conda (æ¨è)

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/yourusername/minimind.git
cd minimind

# åˆ›å»ºå¹¶æ¿€æ´» Conda ç¯å¢ƒ
conda env create -f environment/environment.yml
conda activate mokiomind-video
```

#### æ–¹æ³• 2: ä½¿ç”¨ pip

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/yourusername/minimind.git
cd minimind

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install torch>=2.9.0 transformers>=4.57.1 numpy>=2.3.4 pandas>=2.3.3
```

### æ¨ç†ç¤ºä¾‹

```python
from model.model import MokioMindConfig, MokioMindForCausalLM
import torch

# åˆå§‹åŒ–é…ç½®
config = MokioMindConfig(
    hidden_size=512,
    num_attention_heads=8,
    num_key_value_heads=2,  # GQA: 4å€å‹ç¼©
    num_hidden_layers=8,
    vocab_size=6400,
    max_position_embeddings=32768,
    flash_attention=True,
)

# å®ä¾‹åŒ–æ¨¡å‹
model = MokioMindForCausalLM(config)

# æ„é€ è¾“å…¥
input_ids = torch.randint(0, config.vocab_size, (1, 128))  # (batch, seq_len)

# å‰å‘ä¼ æ’­
outputs = model(input_ids)
logits = outputs.logits  # (batch, seq_len, vocab_size)

print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
```

### ä½¿ç”¨ KV Cache ç”Ÿæˆ

```python
# é¢„å¡«å……é˜¶æ®µ
outputs = model(input_ids, use_cache=True)
past_key_values = outputs.past_key_values

# ç”Ÿæˆä¸‹ä¸€ä¸ª token
new_token_id = torch.tensor([[next_token_id]])
outputs = model(
    new_token_id,
    past_key_values=past_key_values,
    use_cache=True
)
```

## ğŸ“Š æ¨¡å‹è§„æ ¼

### å‚æ•°è§„æ¨¡è¡¨

| è§„æ ¼ | Hidden Size | Layers | Heads (Q/KV) | å‚æ•°é‡ |
|------|-------------|--------|--------------|--------|
| Tiny | 512 | 8 | 8/2 | \~25M |
| Small | 768 | 12 | 12/3 | \~60M |
| Base | 1024 | 16 | 16/4 | \~120M |
| Large | 2048 | 24 | 32/8 | \~500M |

### GQA æ˜¾å­˜èŠ‚çœå¯¹æ¯”

ä»¥ Llama-7B ç»“æ„ä¸ºä¾‹ (Batch=32, Len=4096):

| æ¨¡å¼ | KV Heads | KV Cache (Batch=1, Seq=2048) | èŠ‚çœ |
|------|---------|------------------------------|------|
| MHA | 32 | \~2.0 GB | åŸºå‡† |
| GQA-8 | 8 | \~0.5 GB | 75% èŠ‚çœ |
| MQA | 1 | \~0.06 GB | 97% èŠ‚çœ |

## ğŸ› ï¸ è¿›é˜¶åŠŸèƒ½

### Flash Attention å®ç°

è‡ªåŠ¨æ£€æµ‹ç¯å¢ƒå¹¶ä½¿ç”¨ä¼˜åŒ–ç®—å­ï¼š

```python
if torch.cuda.is_available() and torch.version.cuda >= "11.8":
    # ä½¿ç”¨ Flash Attention v2 (è‡ªåŠ¨)
    output = F.scaled_dot_product_attention(q, k, v, is_causal=True)
else:
    # æ…¢é€Ÿå…œåº•å®ç°
    scores = (q @ k.transpose(-2, -1)) / sqrt(head_dim)
    scores = softmax(scores + causal_mask)
    output = scores @ v
```

### YaRN é•¿æ–‡æœ¬æ‰©å±•

é€šè¿‡ä¿®æ”¹é…ç½®å¯ç”¨ YaRNï¼š

```python
config = MokioMindConfig(
    max_position_embeddings=32768,
    rope_scaling={
        "type": "yarn",
        "factor": 4,  # 4å€æ‰©å±•
        "original_max_position_embeddings": 2048,
        "beta_fast": 32,
        "beta_slow": 1,
    }
)
```

### æ··åˆç²¾åº¦ RMSNorm

ä¸ºäº†æ•°å€¼ç¨³å®šæ€§ï¼ŒRMSNorm å†…éƒ¨å¼ºåˆ¶ä½¿ç”¨ FP32ï¼š

```python
def forward(self, x):
    # å¼ºåˆ¶è½¬æ¢ä¸º FP32 è¿›è¡Œç»Ÿè®¡é‡è®¡ç®—
    x_float = x.float()
    normed = self._norm_(x_float)
    # è½¬æ¢å›åŸå§‹ç²¾åº¦
    return (normed * self.weights).type_as(x)
```
